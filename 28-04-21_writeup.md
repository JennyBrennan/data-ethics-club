# Data Ethics Club: [We created poverty. Algorithms won't make that go away](https://www.theguardian.com/commentisfree/2018/may/13/we-created-poverty-algorithms-wont-make-that-go-away)
<!--Please don't edit the info panel below-->

:::warning
### :arrow_forward: What's this document?

#### :writing_hand: Let's write together!
We're trying to write up these discussions and include input from everyone.
We hope you'll join us and help us to make any write-ups of the discussion a little more representative of everyone's point of view.

We also hope that through doing this, we'll open up the possibility for more collaborative writing together in the future, e.g. through a perspective article.
That's if there's any appetite from you to do that.

#### :computer: Writing in Markdown
We're using HackMD to write a collaborative Markdown document. 
Markdown is a format for writing text that displays nicely on websites.
On the left you can edit, and on the right you can see view.

#### :grey_question: Getting Markdown help
There is a question mark symbol at the top of the screen that will bring up a cheat sheet, e.g. *write between single asterixes to write in italics* **or double asterixes for bold**.
You can also use the buttons at the top of the edit panel.
:::

## Welcome
Hi :wave:, welcome to Data Ethics Club! 
Thank you for being here!

Here are some quick useful links:
- [This Document](https://hackmd.io/@nataliethurlby/DEC-poverty-algorithms)
- [Code of Conduct](https://github.com/very-good-science/data-ethics-club/blob/main/code_of_conduct.MD)
- [Our GitHub page](https://github.com/very-good-science/data-ethics-club)
- [This week's discussion material](https://www.theguardian.com/commentisfree/2018/may/13/we-created-poverty-algorithms-wont-make-that-go-away)

## Introductions
Please introduce yourself here.
Feel free to use a pseudoname (this is a public document).
If you provide a GitHub username, I'll use those to credit you for discussions :speech_balloon: and/or writing :writing_hand:  on our GitHub 

__Name, Job title, Affiliation, GitHub, Twitter, Emoji to describe your day__
- Natalie Thurlby, Data Scientist, University of Bristol, [NatalieThurlby](https://github.com/NatalieThurlby/), [@StatalieT](https://twitter.com/StatalieT), :sun_with_face: 
- Nina Di Cara, PhD Student, University of Bristol, [ninadicara](https://github.com/ninadicara/), [@ninadicara](https://twitter.com/ninadicara), :writing_hand:
- Huw Day, Maths PhDoer, Bristol
- Robin Dasler, data product manager on hiatus, [github:daslerr](https://github.com/daslerr)
- Paul Lee, investor, @pclee27 www.senseoffairness.blog
- Kamilla Wells, Citizen Developer, Australia [Kamilla Wells](https://www.linkedin.com/in/kamilla-wells/)

## Discussion
Each week, we split into breakout rooms of 4-6 people to discuss the material. 
Please make space for one another to talk - keep your eyes open :eyes: for people with their hands up :hand: and invite them to talk.

As always we have provided some discussion points to get the conversation moving, but feel free to discuss anything relating to the materials!

::: info
### :information_source:  Notes on writing
#### Writing things down is optional

The following are all good options:
- :heavy_check_mark: Writing some notes in here as you discuss.
- :heavy_check_mark: Writing some notes in here up to a week after the discussion at any time.
- :heavy_check_mark: Not writing any notes in here at any time.

#### What to write
Suggestions for what to write down (if you want to):
- Any interesting quotes from the discussion
- Links to other material that came up in the discussion
- Parts of the reading material that you felt particularly strongly about
:::

### Discussion

#### Overall summary
Software fixes for hardware problems. 
We don't want to make difficult decisions, so it's easier to pass that decision to an algorithm who can take the blame. 
Pessimitic about what you can do to do good with algorithms. Is it important 

Argument against optimisation wasn't the point - data scientists decide what to optimise for, and it what context. Is it so bad to optimise things that will help people? (Like who is most likely to surive a kidney transplant). Algorithms can add value. Data scientists could help optimise things at a greater level

Difficult to decide how 'deserving' you are.  
If you automated a problem, you won't get creative solutions. Other good algorithm examples - food waste. Optimisation is useful, but you have to marry it with policy proposals.   
How can we help? You constantly need to be ethically reviewing. Difficult if you're the sole data scientist in your context.

Poorer people are the "guinea pigs" for the algorithms of the future.

#### Suggested Questions

- **Q1**: Think of a time when you were in serious need of help. Where would you put yourself on the "spectrum of deservingness" of assistance? Is this a reasonable question?
- **Q2**: In projects that involve direct impacts on people's lives, does everything need to be automated and optimized?
- **Q3**: In what ways can data-scientists positively contribute to poverty-relief projects and avoid reinforcing societal inequalities by outsourcing our ethical choices to machines?
- **Bonus Question:** What change would you like to see on the basis of this piece? Who has the power to make that change?

#### Room 1

##### Q1
- We can all understand the "efficiency" aspect, but its uncomfortable to think about.
- NHS resourcing: who gets admitted to the ICU, for sometimes sensible reasons. Also which locations in the country are understaffed.
- Imposing this "deservingness" on groups from the outside. And how can we turn you into a "success".
- The myth of meritocracy is a story the successful tell about themselves, forgetting their starting advantages and luck along the way; its reverse is the blame placed on the unsuccessful for perceived "failure". This means 'deservingness' may be exactly the wrong lens to look through.

##### Q2
- Local government continually being pitched software to "smartify" certain processes. Coming from outside and not understanding how local government works. Can be very expensive and well-marketed.
- Job applications
- We in generally need more empathy and should not forget to be human when that's the better answer to the challenge.
- Automated does not equal digital
 
##### Q3
- Must keep humans in the loop. Make the case-workers job easier to help individuals.
- Estimating how impact of policies at neighborhood levels. Must beware of all the data holders and their restrictions.

##### Bonus question
- Pushing back the question onto the policy makers the austerity decissions. Particularly housing.

##### Misc
- There's a sense that technology becomes a solution to cowardice. Humans avoiding hard decisions, not dealing with the lack of resources but using some route to deal with the issues that will automatically arise because of it.

#### Room 2
Disappointing because: it's true that you can't fix the roblem of not enough resources with better distribution, but why not also try for better distribution?
How effective are these technologies? If they are effective in reducing harm, then obviously we do want to use them. If they are ineffective then it adds insult to injury because you're diverting money away from (e.g. social work/pepole directly) towards tech companies.
In Covid, people have decided who gets life support and who doesn't: so can we really say that algorithms are just used for people to hide behind?
Undeservingness: this terminology harks back to Victorian ideas of deserving/undeserving poor - but deciding which resource allocation will be most effective doesn't usually imply making a judgement about the morality of recipients.  
Fear of optimisation for valid reasons.
What are we optimising for? When you carry out any optimization you decide what you're trying to optimize, under what constraints. 

##### Q1

##### Q2
What's wrong with optimising things if it helps?
Maybe they can't do everything, but if they can ensure the most vulnerable get help (ish, or better than human decisions) then is it causing extra harm?

##### Q3



##### Bonus question

##### Misc

#### Room 3
##### Q1 Tough question, lots of context goes into trying to answer it. Attempts at self-assessment... but what's the right criteria?

##### Q2 Not everything. Resource management balancing act. Resources are there, some people have been systemically shut out of accessing them. An automation will not provide a solution to that access problem. 
Lose the chance for creative solutions. 

Consider though the case of food waste... automation and optimisation could provide great good there. But doesn't give us a free ride to avoid looking at other deeper issues e.g. dumpster locking/participation. 

##### Q3 Ethics shouldn't be a side hustle. Continuous ethical consideration when in project. If for example, hired as the data scientist on a project like this, how much scope will you have to try to help make change?

##### Bonus question

##### Misc

#### Room 4

##### Q1

##### Q2

##### Q3

##### Bonus question

##### Misc


## Voting
1. [Critical Perspectives on Computer Vision](https://slideslive.com/38923500/critical-perspectives-on-computer-vision) - a ~20 minute video about image recognition/categorisation by Emily Denton, a Senior Research Scientist on Googleâ€™s Ethical AI team
2. [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/pdf/1607.06520.pdf) - paper about how to make word embeddings in language models less biased
3. [A manifesto for big team science](https://psyarxiv.com/2mdxh/) - preprint about barriers to doing science as a team (based in psychology)

## After this session
You have a week to add anything else that you'd like to to this document. 
After that, we'll try to make this document a little more cohesive, then we'll send a link around to the write up of the discussion in the next mailing list email.

## Feedback on the format
Please feel free to leave us some notes below on how the discussion group went for you this time, positive or negative, and any suggestions to improve (you can always [email us](grp-ethicaldatascience@groups.bristol.ac.uk) instead). 
We do read these and make changes :sparkles: 

* Suggestion here
* Another suggestion here